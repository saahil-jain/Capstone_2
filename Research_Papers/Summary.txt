######################################################################################################################################################################################################################################################################################################################################################################################

Multi-Content GAN for Few-Shot Font Style Transfer
Samaneh Azadi, Matthew Fisher, Vladimir Kim, Zhaowen Wang, Eli Shechtman, Trevor Darrell
UC Berkeley,
Adobe Research

Summary:
The paper propose an end-to-end stacked conditional GAN model to acheive style transfer for fonts. The paper attempts to transfer both the typographic stylization, like serifs and ears, as well as the textual stylization ,like color gradients and effects.
The project consist of two Machine learning models, first a stacked cGAN architecture to predict the coarse glyph shapes, and next an ornamentation network to predict color and texture of the final glyphs. The two models are trained together and specialized for each font. 
For each font the models are trained on a few letters and then the style of these few alphabets is then applied to all the other letters of the alphabet.
The collected dataset for this approach includes 10,000 different fonts styles of the english alphabets, which include fonts from movie titles and and gradient fonts. 
As per our observations the style transfer acheived using this method was the best of all the other work in this area, however the accuracy of style transfer is good only for letters very similar to the letters in the training set. 

Pros:
Achieves good level of style transfer for letters similar to training letters.

Cons: 
Style transfer is good only for letters similar to the training data.
Works only for letters of the same language.
Model can't be applied to languages like Kannada as the letters itself vary a lot.



######################################################################################################################################################################################################################################################################################################################################################################################

Typeface Completion with Generative Adversarial Networks
Yonggyu Park, Junhyun Lee, Yookyung Koh, Inyeop Lee, Jinhyuk Lee, Jaewoo Kang
Department of Computer Science and Engineering
Korea University

Summary:
The paper aims to build a model that takes the image of one character of a font as input and generates all the other characters of the alphabet in the same font of the input character.
The paper proposes Typeface Completion Network, which TCN consists of two encoders, a generator and a discriminator. the two encoders, typeface encoder and content encoder, each return a vector that combines the different kinds of information. The generator, receives input and target character labels along with the two vectors from the encoders and generates the final output image. The discriminator determines if the generated image is real and this is repeated until the generated images are of desirable quality.
the concept is applied to fonts of English as well as Chinese and acheives style transfer of reasonably good quality. The English dataset consists of 907 different fonts of the uppercase alphabets. The Chinese dataset consists of 150 different fonts of the 1000 most used characters.

Pros:
Can generate same fonts for all letters of the language with just one input letter.

Cons:
Hight data dependency. 
Style learning from input letter cannot be extrapolated to letters outside the training set.



######################################################################################################################################################################################################################################################################################################################################################################################

Attribute2Font: Creating Fonts You Want From Attributes
YIZHI WANG,  China YUE GAO,  China ZHOUHUI LIAN
Wangxuan Institute of Computer Technology
Peking University, China

Summary:
The paper aims to build a model which is capable of generating glyph images according to user-specified font attributes. The attributes are -
Angular, Bad, Disorderly, Happy, Italic, Serif, Thin and Wide. 

Pros:
Can generate style consistent fonts for an incredibly large combination of attribute values.
Can focus more on specific attributes and less on other attributes.
Solution would work for any language If the abundant data is available.

Cons:
Large amounts of labelled data needed.
Can't work for Indian languages like Kannada as fonts itself are limited. 


